{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make GropKFold(by pois) to avoid leakage of the data between train and test split. According to the fact that we have two poi columns for pairs there is no way to make cross-validation split using GroupKFold from sklearn. So let's write split function by ourselves. At the end we will have train\\test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import time\n",
    "from joblib import dump, load\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsMatched = pd.read_csv('./pairs/custom_pairs.csv')\n",
    "pairsNonMatched = pd.read_csv('./pairs/nonmatching_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert poi column to poi1 and poi2 columns for pairs Matched to concatenate with other dfs\n",
    "pairsMatched.insert(5,'poi1',pairsMatched['poi'].values)\n",
    "pairsMatched = pairsMatched.rename(columns = {\"poi\": \"poi2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2241955, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairsFull = pd.concat([pairsMatched, pairsNonMatched], ignore_index = True)\n",
    "pairsFull.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bunch():\n",
    "    def __init__(self, columns, out_dir, fold, purpose = 'train'):\n",
    "        self.pois_set = set()\n",
    "        self.df = pd.DataFrame(columns = columns)\n",
    "        self.match_count = 1\n",
    "        self.nonmatch_count = 1\n",
    "        self.length = 1\n",
    "        self.outpath = out_dir + 'Fold_' + str(fold) + '_' + purpose + '.csv'\n",
    "    \n",
    "    def add(self, row_to_add):\n",
    "        self.pois_set.add(row_to_add.poi1)\n",
    "        self.pois_set.add(row_to_add.poi2)\n",
    "        self.length += 1\n",
    "        if row_to_add.match:\n",
    "            self.match_count += 1\n",
    "        else:\n",
    "            self.nonmatch_count += 1\n",
    "\n",
    "        self.df = pd.concat([self.df,row_to_add.to_frame().transpose()], ignore_index = True)\n",
    "        if len(self.df)>100:\n",
    "            self.to_csv(self.df)\n",
    "\n",
    "    def to_csv(self, df):\n",
    "        df.to_csv(self.outpath, mode='a', header=not os.path.exists(self.outpath), index = False)\n",
    "        self.df = pd.DataFrame(columns = list(self.df.columns))\n",
    "            \n",
    "        \n",
    "        \n",
    "def customGroupKFOLD(data, n_splits, test_size = 0.3, out_dir  = './folds/'):\n",
    "    for fold in range(n_splits):\n",
    "        start_time = time.time()\n",
    "        data = data.sample(frac = 1).reset_index(drop = True)\n",
    "        train = Bunch(list(data.columns), out_dir, fold, 'train')\n",
    "        test = Bunch(list(data.columns),out_dir, fold, 'test')\n",
    "        for row_id in tqdm(range(len(data))):\n",
    "            current_row = data.iloc[row_id]\n",
    "            if test.length/(train.length + test.length) > test_size:\n",
    "                #trying to add to the train\n",
    "                if current_row.poi1 not in test.pois_set and current_row.poi2 not in test.pois_set:\n",
    "                    train.add(current_row)\n",
    "                elif current_row.poi1 not in train.pois_set and current_row.poi2 not in train.pois_set:\n",
    "                    test.add(current_row)\n",
    "            else:\n",
    "                #trying to add to the test\n",
    "                if current_row.poi1 not in train.pois_set and current_row.poi2 not in train.pois_set:\n",
    "                    test.add(current_row)\n",
    "                elif current_row.poi1 not in test.pois_set and current_row.poi2 not in test.pois_set:\n",
    "                    train.add(current_row)\n",
    "        train.to_csv(train.df)\n",
    "        test.to_csv(test.df)\n",
    "        display(f'Fold {fold} finished!')\n",
    "        display(f'Train length: {train.length - 1} Test length: {test.length - 1}')\n",
    "        display(f'Train match/nonmatch: {train.match_count/train.nonmatch_count} Test match/nonmatch: {test.match_count/test.nonmatch_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 2241955/2241955 [24:19<00:00, 1536.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fold 0 finished!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Train length: 1415363 Test length: 602448'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Train match/nonmatch: 0.8262915583862585 Test match/nonmatch: 1.0609545833960508'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input df and number of folds we want. also we could specify directory to save folds \n",
    "#and test_size, but I'm happy with default ones\n",
    "customGroupKFOLD(pairsFull, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
